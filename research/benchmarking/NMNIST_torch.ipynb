{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import snntorch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.set_per_process_memory_fraction(0.85, device=0)\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tonic\n",
    "from tonic import datasets, transforms\n",
    "import torchvision as tv\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import namedtuple\n",
    "\n",
    "State = namedtuple(\"State\", \"obs labels\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://prod-dcd-datasets-public-files-eu-west-1.s3.eu-west-1.amazonaws.com/1afc103f-8799-464a-a214-81bb9b1f9337 to ./tmp/data/NMNIST/train.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "674a232613f14f468861744bad5539c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1011893601 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./tmp/data/NMNIST/train.zip to ./tmp/data/NMNIST\n",
      "Downloading https://prod-dcd-datasets-public-files-eu-west-1.s3.eu-west-1.amazonaws.com/a99d0fee-a95b-4231-ad22-988fdb0a2411 to ./tmp/data/NMNIST/test.zip\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a51c16464754e2baeba8ef39da04948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/169674850 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./tmp/data/NMNIST/test.zip to ./tmp/data/NMNIST\n"
     ]
    }
   ],
   "source": [
    "sensor_size = tonic.datasets.NMNIST.sensor_size\n",
    "\n",
    "# Denoise removes isolated, one-off events\n",
    "# time_window\n",
    "frame_transform = transforms.Compose([\n",
    "                                      transforms.ToFrame(sensor_size=sensor_size, \n",
    "                                                         n_time_bins=64)\n",
    "                                     ])\n",
    "\n",
    "train_dataset = tonic.datasets.NMNIST(save_to='./tmp/data', transform=frame_transform, train=True)\n",
    "test_dataset = tonic.datasets.NMNIST(save_to='./tmp/data', transform=frame_transform, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = iter(DataLoader(train_dataset, batch_size=len(train_dataset),\n",
    "                          collate_fn=tonic.collation.PadTensors(batch_first=True), drop_last=True, shuffle=False))\n",
    "        \n",
    "x_train, y_train = next(train_dl)\n",
    "x_train, y_train = x_train.to(torch.uint8), y_train.to(torch.uint8)\n",
    "x_train, y_train = x_train.to(device), y_train.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(dataset):\n",
    "    x, y = dataset\n",
    "\n",
    "    cutoff = y.shape[0] % batch_size\n",
    "\n",
    "    indices = torch.randperm(y.shape[0])[:-cutoff]\n",
    "    obs, labels = x[indices], y[indices]\n",
    "\n",
    "\n",
    "    obs = torch.reshape(obs, (-1, batch_size) + obs.shape[1:])\n",
    "    labels = torch.reshape(labels, (-1, batch_size)) # should make batch size a global\n",
    "\n",
    "    return State(obs=obs, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = iter(DataLoader(test_dataset, batch_size=len(test_dataset),\n",
    "                          collate_fn=tonic.collation.PadTensors(batch_first=True), drop_last=True, shuffle=False))\n",
    "        \n",
    "x_test, y_test = next(test_dl)\n",
    "x_test, y_test = x_test.to(torch.uint8), y_test.to(torch.uint8)\n",
    "x_test, y_test = x_test.to(device), y_test.to(device)\n",
    "x_test, y_test = shuffle((x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Initialize Network\n",
    "net = nn.Sequential(nn.Conv2d(2, 12, 5),\n",
    "                    snn.Leaky(beta=torch.ones(10)*0.5, learn_beta=True, init_hidden=True),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    nn.Conv2d(12, 32, 5),\n",
    "                    snn.Leaky(beta=torch.ones(10)*0.5, learn_beta=True, init_hidden=True),\n",
    "                    nn.MaxPool2d(2),\n",
    "                    nn.Flatten(),\n",
    "                    nn.Linear(32*5*5, 10),\n",
    "                    snn.Leaky(beta=torch.ones(10)*0.5, learn_beta=True, init_hidden=True, output=True)\n",
    "                    ).to(device)\n",
    "\n",
    "# this time, we won't return membrane as we don't need it \n",
    "\n",
    "def forward_pass(net, data):\n",
    "  print(data.shape)\n",
    "  spk_rec = []\n",
    "  utils.reset(net)  # resets hidden states for all LIF neurons in net\n",
    "\n",
    "  for step in range(data.size(0)):  # data.size(0) = number of time steps\n",
    "      spk_out, mem_out = net(data[step])\n",
    "      spk_rec.append(spk_out)\n",
    "  \n",
    "  return torch.stack(spk_rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss(label_smoothing=0.3)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4)\n",
    "acc = lambda predictions, targets : (torch.argmax(predictions, axis=-1) == targets).sum().item() / len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 300\n",
    "loss_hist = []\n",
    "counter = 0\n",
    "\n",
    "\n",
    "# Outer training loop\n",
    "for epoch in range(num_epochs):    \n",
    "    \n",
    "    train_batch = shuffle((x_train, y_train))\n",
    "    train_data, targets = train_batch\n",
    "    \n",
    "    \n",
    "    # Minibatch training loop\n",
    "    for data, targets in zip(train_data, targets):\n",
    "\n",
    "        # forward pass\n",
    "        net.train()\n",
    "        out_V = forward(net, data)\n",
    "        # initialize the loss & sum over time\n",
    "        loss_val = loss(torch.sum(out_V, axis=-2), targets)\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Store loss history for future plotting\n",
    "    loss_hist.append(loss_val.item())\n",
    "\n",
    "\n",
    "# Test set\n",
    "with torch.no_grad():\n",
    "    denominator = y_test[0]\n",
    "    test_acc = 0\n",
    "    batch_acc = []\n",
    "    for test_data, test_targets in zip(x_test, y_test):\n",
    "        net.eval()\n",
    "        # Test set forward pass\n",
    "        out_V = net(test_data)\n",
    "        # Test set loss\n",
    "        batch_acc.append( acc(torch.sum(out_V, axis=-2), test_targets) )\n",
    "    \n",
    "    test_acc = np.mean(batch_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[9.558403968811035,\n",
       " 6.229371547698975,\n",
       " 3.955392360687256,\n",
       " 3.6000406742095947,\n",
       " 3.3873300552368164,\n",
       " 3.3082501888275146,\n",
       " 3.3575539588928223,\n",
       " 3.0741758346557617,\n",
       " 2.8566598892211914,\n",
       " 2.754401206970215,\n",
       " 2.689972400665283,\n",
       " 2.703676223754883,\n",
       " 2.647325277328491,\n",
       " 2.479779005050659,\n",
       " 2.46976375579834,\n",
       " 2.428328275680542,\n",
       " 2.4558167457580566,\n",
       " 2.373805046081543,\n",
       " 2.296424388885498,\n",
       " 2.297205924987793,\n",
       " 2.298617362976074,\n",
       " 2.3695068359375,\n",
       " 2.320899486541748,\n",
       " 2.279393196105957,\n",
       " 2.2895267009735107,\n",
       " 2.2929110527038574,\n",
       " 2.1684398651123047,\n",
       " 2.2434680461883545,\n",
       " 2.18837833404541,\n",
       " 2.2598612308502197,\n",
       " 2.170142650604248,\n",
       " 2.178297758102417,\n",
       " 2.178230047225952,\n",
       " 2.1480274200439453,\n",
       " 2.097745656967163,\n",
       " 2.114993095397949,\n",
       " 2.159008741378784,\n",
       " 2.1527669429779053,\n",
       " 2.1277217864990234,\n",
       " 2.1327974796295166,\n",
       " 2.1317038536071777,\n",
       " 2.1158857345581055,\n",
       " 2.125640869140625,\n",
       " 2.0982773303985596,\n",
       " 2.083098888397217,\n",
       " 2.0460376739501953,\n",
       " 2.093351364135742,\n",
       " 2.0999112129211426,\n",
       " 2.061932325363159,\n",
       " 2.0191469192504883,\n",
       " 2.029412269592285,\n",
       " 2.058676242828369,\n",
       " 2.036670207977295,\n",
       " 2.048281669616699,\n",
       " 2.0722458362579346,\n",
       " 2.0839834213256836,\n",
       " 2.0935375690460205,\n",
       " 2.039905548095703,\n",
       " 2.0261800289154053,\n",
       " 1.9995462894439697,\n",
       " 2.024599075317383,\n",
       " 2.0271286964416504,\n",
       " 2.0002284049987793,\n",
       " 2.0208168029785156,\n",
       " 2.059208393096924,\n",
       " 2.00380802154541,\n",
       " 1.9734877347946167,\n",
       " 1.991959810256958,\n",
       " 2.016829490661621,\n",
       " 1.992745041847229,\n",
       " 1.9874006509780884,\n",
       " 2.0106029510498047,\n",
       " 1.9436397552490234,\n",
       " 1.9509477615356445,\n",
       " 1.9415137767791748,\n",
       " 1.9912948608398438,\n",
       " 1.9490084648132324,\n",
       " 1.98067307472229,\n",
       " 1.9478569030761719,\n",
       " 1.9444310665130615,\n",
       " 1.9517661333084106,\n",
       " 1.9496080875396729,\n",
       " 1.9423837661743164,\n",
       " 1.9583104848861694,\n",
       " 1.937196969985962,\n",
       " 1.9965699911117554,\n",
       " 1.9244225025177002,\n",
       " 1.9876091480255127,\n",
       " 1.9428699016571045,\n",
       " 1.9581143856048584,\n",
       " 1.8980166912078857,\n",
       " 1.933426856994629,\n",
       " 1.958754301071167,\n",
       " 1.9449124336242676,\n",
       " 1.8883898258209229,\n",
       " 1.9289391040802002,\n",
       " 1.929905652999878,\n",
       " 1.9023211002349854,\n",
       " 1.894822359085083,\n",
       " 1.9335401058197021,\n",
       " 1.9115424156188965,\n",
       " 1.9430596828460693,\n",
       " 1.908921480178833,\n",
       " 1.9227662086486816,\n",
       " 1.8718113899230957,\n",
       " 1.9142582416534424,\n",
       " 1.9306082725524902,\n",
       " 1.9048261642456055,\n",
       " 1.8720890283584595,\n",
       " 1.873234748840332,\n",
       " 1.8873058557510376,\n",
       " 1.8756725788116455,\n",
       " 1.8777365684509277,\n",
       " 1.872248649597168,\n",
       " 1.851712703704834,\n",
       " 1.8726189136505127,\n",
       " 1.8885667324066162,\n",
       " 1.848158597946167,\n",
       " 1.862648367881775,\n",
       " 1.8750269412994385,\n",
       " 1.8392674922943115,\n",
       " 1.9001898765563965,\n",
       " 1.855541706085205,\n",
       " 1.8789432048797607,\n",
       " 1.8480515480041504,\n",
       " 1.8368511199951172,\n",
       " 1.836277723312378,\n",
       " 1.8875598907470703,\n",
       " 1.8839768171310425,\n",
       " 1.860551357269287,\n",
       " 1.8939828872680664,\n",
       " 1.8609167337417603,\n",
       " 1.8917995691299438,\n",
       " 1.8534810543060303,\n",
       " 1.8077337741851807,\n",
       " 1.8098158836364746,\n",
       " 1.8508882522583008,\n",
       " 1.839094877243042,\n",
       " 1.848276138305664,\n",
       " 1.8374128341674805,\n",
       " 1.8365013599395752,\n",
       " 1.831918716430664,\n",
       " 1.845494031906128,\n",
       " 1.8429417610168457,\n",
       " 1.8563429117202759,\n",
       " 1.8309721946716309,\n",
       " 1.8023791313171387,\n",
       " 1.8564521074295044,\n",
       " 1.8204690217971802,\n",
       " 1.8121564388275146,\n",
       " 1.86305832862854,\n",
       " 1.814255952835083,\n",
       " 1.8311944007873535,\n",
       " 1.8124916553497314,\n",
       " 1.7968199253082275,\n",
       " 1.7968957424163818,\n",
       " 1.8402185440063477,\n",
       " 1.7782474756240845,\n",
       " 1.819481611251831,\n",
       " 1.8325295448303223,\n",
       " 1.8080401420593262,\n",
       " 1.79668128490448,\n",
       " 1.7959685325622559,\n",
       " 1.798243761062622,\n",
       " 1.7604954242706299,\n",
       " 1.8161776065826416,\n",
       " 1.8075461387634277,\n",
       " 1.7858713865280151,\n",
       " 1.818433403968811,\n",
       " 1.7903666496276855,\n",
       " 1.7959336042404175,\n",
       " 1.7784457206726074,\n",
       " 1.8319156169891357,\n",
       " 1.7803993225097656,\n",
       " 1.7834184169769287,\n",
       " 1.79714035987854,\n",
       " 1.8165642023086548,\n",
       " 1.7730995416641235,\n",
       " 1.789679765701294,\n",
       " 1.8004779815673828,\n",
       " 1.7841848134994507,\n",
       " 1.7833938598632812,\n",
       " 1.7674927711486816,\n",
       " 1.8062775135040283,\n",
       " 1.778643250465393,\n",
       " 1.7754199504852295,\n",
       " 1.7924156188964844,\n",
       " 1.759161353111267,\n",
       " 1.7597054243087769,\n",
       " 1.7610563039779663,\n",
       " 1.754209041595459,\n",
       " 1.7909823656082153,\n",
       " 1.796364188194275,\n",
       " 1.7626264095306396,\n",
       " 1.7354578971862793,\n",
       " 1.7913553714752197,\n",
       " 1.7571690082550049,\n",
       " 1.7656126022338867,\n",
       " 1.7763432264328003,\n",
       " 1.7650508880615234,\n",
       " 1.7581807374954224,\n",
       " 1.7815399169921875,\n",
       " 1.8106234073638916,\n",
       " 1.739544153213501,\n",
       " 1.7696199417114258,\n",
       " 1.751425862312317,\n",
       " 1.7479591369628906,\n",
       " 1.77006196975708,\n",
       " 1.756376028060913,\n",
       " 1.7502567768096924,\n",
       " 1.770977258682251,\n",
       " 1.7481743097305298,\n",
       " 1.739193081855774,\n",
       " 1.7641578912734985,\n",
       " 1.7461977005004883,\n",
       " 1.7493550777435303,\n",
       " 1.7605916261672974,\n",
       " 1.735469937324524,\n",
       " 1.7383685111999512,\n",
       " 1.738748550415039,\n",
       " 1.753109335899353,\n",
       " 1.7364816665649414,\n",
       " 1.7388077974319458,\n",
       " 1.754600167274475,\n",
       " 1.7484462261199951,\n",
       " 1.7206120491027832,\n",
       " 1.729905128479004,\n",
       " 1.7482805252075195,\n",
       " 1.7263178825378418,\n",
       " 1.7449393272399902,\n",
       " 1.7542433738708496,\n",
       " 1.7358343601226807,\n",
       " 1.733576774597168,\n",
       " 1.7279514074325562,\n",
       " 1.7144947052001953,\n",
       " 1.7637536525726318,\n",
       " 1.7047076225280762,\n",
       " 1.7491347789764404,\n",
       " 1.724815845489502,\n",
       " 1.7011477947235107,\n",
       " 1.7049986124038696,\n",
       " 1.7248812913894653,\n",
       " 1.7159779071807861,\n",
       " 1.719161868095398,\n",
       " 1.7382144927978516,\n",
       " 1.727384328842163,\n",
       " 1.742123007774353,\n",
       " 1.7298593521118164,\n",
       " 1.7010259628295898,\n",
       " 1.7202534675598145,\n",
       " 1.7337108850479126,\n",
       " 1.717468500137329,\n",
       " 1.733699917793274,\n",
       " 1.7232367992401123,\n",
       " 1.709599494934082,\n",
       " 1.7506523132324219,\n",
       " 1.7244030237197876,\n",
       " 1.7249349355697632,\n",
       " 1.699506402015686,\n",
       " 1.7404379844665527,\n",
       " 1.7222394943237305,\n",
       " 1.7165114879608154,\n",
       " 1.7271798849105835,\n",
       " 1.7119321823120117,\n",
       " 1.7027335166931152,\n",
       " 1.7047860622406006,\n",
       " 1.711835503578186,\n",
       " 1.7050299644470215,\n",
       " 1.7373491525650024,\n",
       " 1.727769136428833,\n",
       " 1.6850848197937012,\n",
       " 1.739804744720459,\n",
       " 1.7077137231826782,\n",
       " 1.7007019519805908,\n",
       " 1.7146097421646118,\n",
       " 1.696763038635254,\n",
       " 1.704608678817749,\n",
       " 1.7048871517181396,\n",
       " 1.7199153900146484,\n",
       " 1.6939775943756104,\n",
       " 1.6750919818878174,\n",
       " 1.6995283365249634,\n",
       " 1.6990784406661987,\n",
       " 1.6738059520721436,\n",
       " 1.7251650094985962,\n",
       " 1.7218161821365356,\n",
       " 1.6925554275512695,\n",
       " 1.7095928192138672,\n",
       " 1.700764775276184,\n",
       " 1.707093358039856,\n",
       " 1.7089931964874268,\n",
       " 1.7133686542510986,\n",
       " 1.7131671905517578,\n",
       " 1.7183682918548584,\n",
       " 1.72318696975708,\n",
       " 1.6997929811477661,\n",
       " 1.6990127563476562,\n",
       " 1.7011858224868774,\n",
       " 1.752995252609253,\n",
       " 1.7054256200790405]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73095703125"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
