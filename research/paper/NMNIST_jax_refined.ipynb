{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6793a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".85\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import spyx\n",
    "import haiku as hk\n",
    "import optax\n",
    "from jax_tqdm import scan_tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da30d5e6",
   "metadata": {},
   "source": [
    "### NMNIST Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab70fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tonic\n",
    "from tonic import datasets, transforms\n",
    "import torchvision as tv\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from collections import namedtuple\n",
    "\n",
    "State = namedtuple(\"State\", \"obs labels\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01a2e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_size = tonic.datasets.NMNIST.sensor_size\n",
    "\n",
    "# Denoise removes isolated, one-off events\n",
    "# time_window\n",
    "frame_transform = transforms.Compose([\n",
    "                                      transforms.ToFrame(sensor_size=sensor_size, \n",
    "                                                         n_time_bins=64),\n",
    "                                      lambda x: np.packbits(x, axis=0)\n",
    "                                     ])\n",
    "\n",
    "train_dataset = tonic.datasets.NMNIST(save_to='./tmp/data', transform=frame_transform, train=True)\n",
    "test_dataset = tonic.datasets.NMNIST(save_to='./tmp/data', transform=frame_transform, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf6be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = iter(DataLoader(train_dataset, batch_size=len(train_dataset)//6,\n",
    "                          collate_fn=tonic.collation.PadTensors(batch_first=True), drop_last=True, shuffle=True))\n",
    "        \n",
    "x_train, y_train = next(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff2544a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_dl = iter(DataLoader(test_dataset, batch_size=len(test_dataset),\n",
    "#                          collate_fn=tonic.collation.PadTensors(batch_first=True), drop_last=True, shuffle=False))\n",
    "#        \n",
    "#x_test, y_test = next(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "670ea0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = jnp.array(x_train, dtype=jnp.uint8)\n",
    "y_train = jnp.array(y_train, dtype=jnp.uint8)\n",
    "\n",
    "#x_test = jnp.array(x_test, dtype=jnp.uint8)\n",
    "#y_test = jnp.array(y_test, dtype=jnp.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7135a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(dataset, shuffle_rng, batch_size):\n",
    "    x, y = dataset\n",
    "\n",
    "    cutoff = y.shape[0] % batch_size\n",
    "\n",
    "    # perhaps calling rand.perm twice is slower than once and using indices?\n",
    "    indices = jax.random.permutation(shuffle_rng, y.shape[0])[:-cutoff] # this is a bug if cutoff == 0\n",
    "    obs, labels = x[indices], y[indices]\n",
    "\n",
    "    obs = jnp.reshape(obs, (-1, batch_size) + obs.shape[1:])\n",
    "    labels = jnp.reshape(labels, (-1, batch_size)) # should make batch size a global\n",
    "\n",
    "    return State(obs=obs, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f415eb8",
   "metadata": {},
   "source": [
    "### Spyx NMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddc797e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_snn(batch_size, channel_multiplier):\n",
    "\n",
    "    mult = channel_multiplier\n",
    "    \n",
    "    def nmnist_snn(x):\n",
    "\n",
    "        x = hk.BatchApply(hk.Conv2D(12*mult, 5, padding=\"VALID\", data_format=\"NCHW\", with_bias=False))(x.astype(jnp.float32))\n",
    "\n",
    "        core1 = spyx.nn.LIF((12*mult, 30, 30,), beta=0.5, activation=spyx.axn.Axon(spyx.axn.arctan()))\n",
    "        x, V = hk.static_unroll(core1, x, core1.initial_state(x.shape[0]), time_major=False)\n",
    "\n",
    "        fused1 = hk.Sequential([\n",
    "            hk.MaxPool((2,2), (2,2), \"VALID\", channel_axis=-3),\n",
    "            hk.Conv2D(32*mult, 5, padding=\"VALID\", data_format=\"NCHW\", with_bias=False)\n",
    "        ])\n",
    "\n",
    "        x = hk.BatchApply(fused1)(x)\n",
    "\n",
    "        core2 = spyx.nn.LIF(( 32*mult, 11, 11,), beta=0.5, activation=spyx.axn.Axon(spyx.axn.arctan()))\n",
    "        x, V = hk.static_unroll(core2, x, core2.initial_state(x.shape[0]), time_major=False)\n",
    "        \n",
    "        fused2 = hk.Sequential([\n",
    "            hk.MaxPool((2,2), (2,2), \"VALID\", channel_axis=-3),\n",
    "            hk.Flatten(),\n",
    "            hk.Linear(10, with_bias=False)\n",
    "        ])\n",
    "        x = hk.BatchApply(fused2)(x)\n",
    "\n",
    "        core3 = spyx.nn.LIF((10,), beta=0.5, activation=spyx.axn.Axon(spyx.axn.arctan()))\n",
    "        spikes, V = hk.static_unroll(core3, x, core3.initial_state(x.shape[0]), time_major=False)\n",
    "    \n",
    "        return spikes, V\n",
    "    \n",
    "    key = jax.random.PRNGKey(0)\n",
    "    # Since there's nothing stochastic about the network, we can avoid using an RNG as a param!\n",
    "    sample_x, sample_y = shuffle((x_train,y_train),key, batch_size)\n",
    "    SNN = hk.without_apply_rng(hk.transform(nmnist_snn))\n",
    "    params = SNN.init(rng=key, x=jnp.float32(sample_x[0]))\n",
    "    \n",
    "    return SNN, params\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f7422a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(SNN, params, dataset, epochs, batch_size):\n",
    "        \n",
    "    opt = optax.adam(learning_rate=5e-4)\n",
    "    \n",
    "    # create and initialize the optimizer\n",
    "    opt_state = opt.init(params)\n",
    "    grad_params = params\n",
    "        \n",
    "    # define and compile our eval function that computes the loss for our SNN\n",
    "    @jax.jit\n",
    "    def net_eval(weights, events, targets):\n",
    "        readout = SNN.apply(weights, events)\n",
    "        traces, V_f = readout\n",
    "        return spyx.fn.integral_crossentropy(traces, targets) # smoothing needs to be more explicit in docs...\n",
    "        \n",
    "    # Use JAX to create a function that calculates the loss and the gradient!\n",
    "    surrogate_grad = jax.value_and_grad(net_eval) \n",
    "        \n",
    "    rng = jax.random.PRNGKey(0)        \n",
    "    \n",
    "    # compile the meat of our training loop for speed\n",
    "    @jax.jit\n",
    "    def train_step(state, data):\n",
    "        grad_params, opt_state = state\n",
    "        events, targets = data \n",
    "        events = jnp.unpackbits(events, axis=1) # decompress temporal axis\n",
    "        # compute loss and gradient                    # need better augment rng\n",
    "        loss, grads = surrogate_grad(grad_params, events, targets)\n",
    "        # generate updates based on the gradients and optimizer\n",
    "        updates, opt_state = opt.update(grads, opt_state, grad_params)\n",
    "        # return the updated parameters\n",
    "        new_state = [optax.apply_updates(grad_params, updates), opt_state]\n",
    "        return new_state, loss\n",
    "    \n",
    "    \n",
    "    # Here's the start of our training loop!\n",
    "    @scan_tqdm(epochs)\n",
    "    def epoch(epoch_state, epoch_num):\n",
    "        curr_params, curr_opt_state = epoch_state\n",
    "\n",
    "        shuffle_rng = jax.random.fold_in(rng, epoch_num)\n",
    "        train_data = shuffle(dataset, shuffle_rng, batch_size)\n",
    "        \n",
    "        # train epoch\n",
    "        end_state, train_loss = jax.lax.scan(\n",
    "            train_step,# func\n",
    "            [curr_params, curr_opt_state],# init\n",
    "            train_data,# xs\n",
    "            train_data.obs.shape[0]# len\n",
    "        )\n",
    "                    \n",
    "        return end_state, jnp.mean(train_loss)\n",
    "    # end epoch\n",
    "    \n",
    "    # epoch loop\n",
    "    start = time()\n",
    "    final_state, metrics = jax.lax.scan(\n",
    "        epoch,\n",
    "        [grad_params, opt_state], # metric arrays\n",
    "        jnp.arange(epochs), # \n",
    "        epochs # len of loop\n",
    "    )\n",
    "    \n",
    "    final_params, loss = final_state\n",
    "    final_params[\"LIF\"][\"beta\"].block_until_ready()\n",
    "    end = time() - start\n",
    "    \n",
    "                \n",
    "    # return our final, optimized network.       \n",
    "    return end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a5cb1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "def run_bench(trials, num_epochs, batch_size, mult):\n",
    "    \n",
    "    SNN, params = build_snn(batch_size, mult)\n",
    "\n",
    "    # need to change how time is measured to match...\n",
    "    times = []\n",
    "    for t in range(trials+1):\n",
    "        times.append(benchmark(SNN, params, (x_train,y_train), num_epochs, batch_size))\n",
    "        print(times[t])\n",
    "    \n",
    "    print(\"Mean:\", np.mean(times[1:]), \"Std. Dev.:\", np.std(times[1:]))\n",
    "    return SNN, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd08a737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394e790009ad418ea25489182179700f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160.31551814079285\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad84b38bcf842928ebddcd87902739f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154.2001552581787\n",
      "Mean: 154.2001552581787 Std. Dev.: 0.0\n"
     ]
    }
   ],
   "source": [
    "snn, p = run_bench(1, 20, 32, 1) # 160 seconds on laptop3060, 10k images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a958ba",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def viz(x):\n",
    "    return snn.apply(p, x)\n",
    "\n",
    "sample_x, sample_y = shuffle((x_train,y_train),jax.random.PRNGKey(0), 32)\n",
    "print(hk.experimental.tabulate(viz)(sample_x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcb27e48-0d9a-461c-932e-dbb2c95fad78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29952,)\n",
      "0 :(29952,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21b93d3dfe743f2a081baee2298a63e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149.29666376113892\n",
      "1 :(29952,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23de146d98a4e5581856cfe0d8d2de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143.64148688316345\n",
      "Mean: 143.64148688316345 Std. Dev.: 0.0\n"
     ]
    }
   ],
   "source": [
    "run_bench(1, 20, 128, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1c5a87-ca0e-451a-a072-087d648d57f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
