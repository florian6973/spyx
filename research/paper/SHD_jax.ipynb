{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6793a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".80\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import spyx\n",
    "import haiku as hk\n",
    "import optax\n",
    "from jax_tqdm import scan_tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da30d5e6",
   "metadata": {},
   "source": [
    "### SHD Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab70fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tonic\n",
    "from tonic import datasets, transforms\n",
    "import torchvision as tv\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from collections import namedtuple\n",
    "\n",
    "State = namedtuple(\"State\", \"obs labels\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d34a193",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _SHD2Raster():\n",
    "    \"\"\" \n",
    "    Tool for rastering SHD samples into frames. Packs bits along the temporal axis for memory efficiency. This means\n",
    "        that the used will have to apply jnp.unpackbits(events, axis=<time axis>) prior to feeding the data to the network.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoding_dim, sample_T = 100):\n",
    "        self.encoding_dim = encoding_dim\n",
    "        self.sample_T = sample_T\n",
    "        \n",
    "    def __call__(self, events):\n",
    "        # tensor has dimensions (time_steps, encoding_dim)\n",
    "        tensor = np.zeros((events[\"t\"].max()+1, self.encoding_dim), dtype=int)\n",
    "        np.add.at(tensor, (events[\"t\"], events[\"x\"]), 1)\n",
    "        #return tensor[:self.sample_T,:]\n",
    "        tensor = tensor[:self.sample_T,:]\n",
    "        tensor = np.minimum(tensor, 1)\n",
    "        tensor = np.packbits(tensor, axis=0)\n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01a2e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_T = 64\n",
    "shd_timestep = 1e-6\n",
    "shd_channels = 700\n",
    "net_channels = 128\n",
    "net_dt = 1/sample_T\n",
    "batch_size = 256\n",
    "\n",
    "obs_shape = tuple([net_channels,])\n",
    "act_shape = tuple([20,])\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Downsample(\n",
    "        time_factor=shd_timestep / net_dt,\n",
    "        spatial_factor=net_channels / shd_channels\n",
    "    ),\n",
    "    _SHD2Raster(net_channels, sample_T=sample_T)\n",
    "])\n",
    "\n",
    "train_dataset = datasets.SHD(\"./data\", train=True, transform=transform)\n",
    "test_dataset = datasets.SHD(\"./data\", train=False, transform=transform)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cf6be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = iter(DataLoader(train_dataset, batch_size=len(train_dataset),\n",
    "                          collate_fn=tonic.collation.PadTensors(batch_first=True), drop_last=True, shuffle=False))\n",
    "        \n",
    "x_train, y_train = next(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff2544a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = iter(DataLoader(test_dataset, batch_size=len(test_dataset),\n",
    "                          collate_fn=tonic.collation.PadTensors(batch_first=True), drop_last=True, shuffle=False))\n",
    "        \n",
    "x_test, y_test = next(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e69c12b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([8156, 8, 128])\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "670ea0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = jnp.array(x_train, dtype=jnp.uint8)\n",
    "y_train = jnp.array(y_train, dtype=jnp.uint8)\n",
    "\n",
    "x_test = jnp.array(x_test, dtype=jnp.uint8)\n",
    "y_test = jnp.array(y_test, dtype=jnp.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7135a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(dataset, shuffle_rng):\n",
    "    x, y = dataset\n",
    "\n",
    "    cutoff = y.shape[0] % batch_size\n",
    "\n",
    "    obs = jax.random.permutation(shuffle_rng, x, axis=0)[:-cutoff]\n",
    "    labels = jax.random.permutation(shuffle_rng, y, axis=0)[:-cutoff]\n",
    "\n",
    "    obs = jnp.reshape(obs, (-1, batch_size) + obs.shape[1:])\n",
    "    labels = jnp.reshape(labels, (-1, batch_size)) # should make batch size a global\n",
    "\n",
    "    return State(obs=obs, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f415eb8",
   "metadata": {},
   "source": [
    "### Spyx SHD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ddc797e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shd_snn(x): \n",
    "        \n",
    "    core = hk.DeepRNN([\n",
    "        hk.Linear(64, with_bias=False),\n",
    "        spyx.nn.LIF((64,), activation=spyx.axn.Axon(spyx.axn.arctan())),\n",
    "        hk.Linear(64, with_bias=False),\n",
    "        spyx.nn.LIF((64,), activation=spyx.axn.Axon(spyx.axn.arctan())),\n",
    "        hk.Linear(20, with_bias=False),\n",
    "        spyx.nn.LI((20,))\n",
    "    ])\n",
    "    \n",
    "    # static unroll for maximum performance\n",
    "    spikes, V = hk.dynamic_unroll(core, x, core.initial_state(x.shape[0]), time_major=False, unroll=32)\n",
    "    \n",
    "    return spikes, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "344ed98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = jax.random.PRNGKey(0)\n",
    "# Since there's nothing stochastic about the network, we can avoid using an RNG as a param!\n",
    "sample_x, sample_y = shuffle((x_train,y_train),key)\n",
    "SNN = hk.without_apply_rng(hk.transform(shd_snn))\n",
    "params = SNN.init(rng=key, x=jnp.float32(sample_x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9f7422a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gd(SNN, params, dataset, epochs=300):\n",
    "        \n",
    "    opt = optax.adam(learning_rate=5e-4)\n",
    "    \n",
    "    # create and initialize the optimizer\n",
    "    opt_state = opt.init(params)\n",
    "    grad_params = params\n",
    "        \n",
    "    # define and compile our eval function that computes the loss for our SNN\n",
    "    @jax.jit\n",
    "    def net_eval(weights, events, targets):\n",
    "        readout = SNN.apply(weights, events)\n",
    "        traces, V_f = readout\n",
    "        return spyx.fn.integral_crossentropy(traces, targets) # smoothing needs to be more explicit in docs...\n",
    "        \n",
    "    # Use JAX to create a function that calculates the loss and the gradient!\n",
    "    surrogate_grad = jax.value_and_grad(net_eval) \n",
    "        \n",
    "    rng = jax.random.PRNGKey(0)        \n",
    "    \n",
    "    # compile the meat of our training loop for speed\n",
    "    @jax.jit\n",
    "    def train_step(state, data):\n",
    "        grad_params, opt_state = state\n",
    "        events, targets = data # fix this\n",
    "        events = jnp.unpackbits(events, axis=1) # decompress temporal axis\n",
    "        # compute loss and gradient                    # need better augment rng\n",
    "        loss, grads = surrogate_grad(grad_params, events, targets)\n",
    "        # generate updates based on the gradients and optimizer\n",
    "        updates, opt_state = opt.update(grads, opt_state, grad_params)\n",
    "        # return the updated parameters\n",
    "        new_state = [optax.apply_updates(grad_params, updates), opt_state]\n",
    "        return new_state, loss\n",
    "    \n",
    "    \n",
    "    # Here's the start of our training loop!\n",
    "    @scan_tqdm(epochs)\n",
    "    def epoch(epoch_state, epoch_num):\n",
    "        curr_params, curr_opt_state = epoch_state\n",
    "\n",
    "        shuffle_rng = jax.random.fold_in(rng, epoch_num)\n",
    "        train_data = shuffle(dataset, shuffle_rng)\n",
    "        \n",
    "        # train epoch\n",
    "        end_state, train_loss = jax.lax.scan(\n",
    "            train_step,# func\n",
    "            [curr_params, curr_opt_state],# init\n",
    "            train_data,# xs\n",
    "            train_data.obs.shape[0]# len\n",
    "        )\n",
    "                    \n",
    "        return end_state, jnp.mean(train_loss)\n",
    "    # end epoch\n",
    "    \n",
    "    # epoch loop\n",
    "    final_state, metrics = jax.lax.scan(\n",
    "        epoch,\n",
    "        [grad_params, opt_state], # metric arrays\n",
    "        jnp.arange(epochs), # \n",
    "        epochs # len of loop\n",
    "    )\n",
    "    \n",
    "    final_params, _ = final_state\n",
    "    \n",
    "                \n",
    "    # return our final, optimized network.       \n",
    "    return final_params, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5a5cb1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_gd(SNN, params, dataset):\n",
    "\n",
    "    @jax.jit\n",
    "    def test_step(params, data):\n",
    "        events, targets = data\n",
    "        events = jnp.unpackbits(events, axis=1)\n",
    "        readout = SNN.apply(params, events)\n",
    "        traces, V_f = readout\n",
    "        acc, pred = spyx.fn.integral_accuracy(traces, targets)\n",
    "        loss = spyx.fn.integral_crossentropy(traces, targets)\n",
    "        return params, [acc, loss, pred, targets]\n",
    "    \n",
    "    test_data = shuffle(dataset, jax.random.PRNGKey(0))\n",
    "    \n",
    "    _, test_metrics = jax.lax.scan(\n",
    "            test_step,# func\n",
    "            params,# init\n",
    "            test_data,# xs\n",
    "            test_data.obs.shape[0]# len\n",
    "    )\n",
    "    \n",
    "    acc = jnp.mean(test_metrics[0])\n",
    "    loss = jnp.mean(test_metrics[1])\n",
    "    preds = jnp.array(test_metrics[2]).flatten()\n",
    "    tgts = jnp.array(test_metrics[3]).flatten()\n",
    "    return acc, loss, preds, tgts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd08a737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9739cbf1b04445481e727ec23b25b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grad_params, metrics = gd(SNN, params, (x_train,y_train), epochs=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7a3a0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([3.3910465, 3.016463 , 3.030699 , 3.0076985, 2.9221492, 2.8107104,\n",
       "       2.7359867, 2.65059  , 2.5880544, 2.5470932, 2.5164132, 2.465876 ,\n",
       "       2.4436922, 2.4118633, 2.3856888, 2.352564 , 2.332061 , 2.315615 ,\n",
       "       2.2930186, 2.2780628, 2.2673588, 2.2505302, 2.2261753, 2.2158225,\n",
       "       2.194442 , 2.1847625, 2.169232 , 2.157136 , 2.1424909, 2.1340435,\n",
       "       2.1233969, 2.1086009, 2.1064436, 2.0974517, 2.0898352, 2.0800953,\n",
       "       2.0742557, 2.067817 , 2.0587747, 2.053098 , 2.053758 , 2.0434794,\n",
       "       2.034027 , 2.0378797, 2.0217361, 2.0174112, 2.0115888, 2.0055044,\n",
       "       1.9960711, 1.9975836, 1.9898484, 1.9836861, 1.9812824, 1.9706731,\n",
       "       1.9612522, 1.9600667, 1.9502194, 1.9454533, 1.9411132, 1.9386741,\n",
       "       1.9352958, 1.927839 , 1.92639  , 1.9222975, 1.9149606, 1.9142834,\n",
       "       1.9100983, 1.9087315, 1.9014016, 1.8975301, 1.8981328, 1.8936834,\n",
       "       1.8925552, 1.8859547, 1.8824438, 1.8849107, 1.8788638, 1.8789203,\n",
       "       1.8728931, 1.8714441, 1.8716774, 1.8650261, 1.862969 , 1.8602042,\n",
       "       1.8552675, 1.8507016, 1.8557642, 1.8538746, 1.8542774, 1.8492283,\n",
       "       1.8424622, 1.8434223, 1.8428924, 1.8392478, 1.8316535, 1.8350915,\n",
       "       1.8313992, 1.8269196, 1.8248738, 1.8195118, 1.8164774, 1.8282608,\n",
       "       1.8205858, 1.8175124, 1.8153615, 1.8120545, 1.8079906, 1.8043151,\n",
       "       1.8068519, 1.8021431, 1.8028805, 1.8037733, 1.8009202, 1.7947619,\n",
       "       1.7922261, 1.7969993, 1.7930679, 1.7921436, 1.7885209, 1.7865162,\n",
       "       1.7846925, 1.7849565, 1.7838248, 1.782717 , 1.7768675, 1.7721171,\n",
       "       1.773855 , 1.7750922, 1.7746986, 1.7728764, 1.7732875, 1.7677621,\n",
       "       1.768684 , 1.7683918, 1.7698998, 1.7660306, 1.764027 , 1.7645346,\n",
       "       1.7663298, 1.7629997, 1.7581933, 1.7632498, 1.7580824, 1.7561194,\n",
       "       1.7579784, 1.7558153, 1.7553418, 1.7529532, 1.7523857, 1.7505592,\n",
       "       1.749127 , 1.7493833, 1.747305 , 1.7455277, 1.744497 , 1.7414367,\n",
       "       1.744422 , 1.7448716, 1.7395647, 1.7436477, 1.7383739, 1.7379516,\n",
       "       1.7404536, 1.7373865, 1.7400848, 1.7409432, 1.7349703, 1.7327204,\n",
       "       1.7290052, 1.7294667, 1.7320275, 1.7292061, 1.7307684, 1.7290097,\n",
       "       1.7287729, 1.7244503, 1.7282922, 1.7246587, 1.7251904, 1.7228132,\n",
       "       1.7235739, 1.720618 , 1.718442 , 1.7191173, 1.7193148, 1.719687 ,\n",
       "       1.7134241, 1.7157352, 1.7162162, 1.714759 , 1.7143409, 1.7145122,\n",
       "       1.7136259, 1.7128072, 1.7136862, 1.7071275, 1.7068237, 1.7071763,\n",
       "       1.7060083, 1.7063177, 1.705672 , 1.7026985, 1.703259 , 1.7020205,\n",
       "       1.7023422, 1.7016567, 1.7015328, 1.7003229, 1.7003909, 1.6966307,\n",
       "       1.6992741, 1.6998947, 1.6999066, 1.6945249, 1.6954966, 1.6950008,\n",
       "       1.6952947, 1.6916841, 1.6948361, 1.6968545, 1.6910477, 1.6906393,\n",
       "       1.6920567, 1.6947122, 1.689308 , 1.6878998, 1.6896596, 1.686852 ,\n",
       "       1.6863364, 1.6862937, 1.6858615, 1.685539 , 1.6882501, 1.6851373,\n",
       "       1.6872344, 1.6840799, 1.6816484, 1.6855409, 1.6844199, 1.6793056,\n",
       "       1.681493 , 1.6803597, 1.6777705, 1.6790397, 1.6791955, 1.6790138,\n",
       "       1.6754521, 1.6764513, 1.6744288, 1.6753664, 1.675034 , 1.6794186,\n",
       "       1.6726539, 1.672659 , 1.672472 , 1.6712132, 1.6735955, 1.6718291,\n",
       "       1.6732728, 1.6688802, 1.6711955, 1.6755103, 1.6728257, 1.6707561,\n",
       "       1.67424  , 1.6724485, 1.6681234, 1.6655933, 1.6707864, 1.6679149,\n",
       "       1.6701663, 1.6647906, 1.6645238, 1.6650786, 1.6654743, 1.6662209,\n",
       "       1.6642926, 1.6608094, 1.6636088, 1.6630603, 1.6640952, 1.6606847,\n",
       "       1.6660243, 1.6624553, 1.6597158, 1.6640639, 1.6622232, 1.6611576,\n",
       "       1.6573477, 1.6559558, 1.658788 , 1.6576893, 1.6559938, 1.6604314,\n",
       "       1.6576806, 1.6543921, 1.654236 , 1.6563418, 1.6540334, 1.6583544],      dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8553879b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7421875 Loss: 2.0260453\n"
     ]
    }
   ],
   "source": [
    "acc, loss, preds, tgts = test_gd(SNN, grad_params, (x_test,y_test))\n",
    "print(\"Accuracy:\", acc, \"Loss:\", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01af1eb",
   "metadata": {},
   "source": [
    "### Use NIR to save our network and then load it up later, in any framework of our choosing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dcf7e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nir\n",
    "export_params = spyx.nir.reorder_layers(params, grad_params)\n",
    "G = spyx.nir.to_nir(export_params, obs_shape, act_shape, 1)\n",
    "nir.write(\"./spyx_shd.nir\", G)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
