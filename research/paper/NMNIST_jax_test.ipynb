{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6793a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".95\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import spyx\n",
    "import haiku as hk\n",
    "import optax\n",
    "from jax_tqdm import scan_tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da30d5e6",
   "metadata": {},
   "source": [
    "### SHD Dataloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab70fd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tonic\n",
    "from tonic import datasets, transforms\n",
    "import torchvision as tv\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from collections import namedtuple\n",
    "\n",
    "State = namedtuple(\"State\", \"obs labels\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01a2e604",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_size = tonic.datasets.NMNIST.sensor_size\n",
    "\n",
    "# Denoise removes isolated, one-off events\n",
    "# time_window\n",
    "frame_transform = transforms.Compose([\n",
    "                                      transforms.ToFrame(sensor_size=sensor_size, \n",
    "                                                         n_time_bins=48),\n",
    "                                      lambda x: np.packbits(x, axis=0)\n",
    "                                     ])\n",
    "\n",
    "train_dataset = tonic.datasets.NMNIST(save_to='./tmp/data', transform=frame_transform, train=True)\n",
    "test_dataset = tonic.datasets.NMNIST(save_to='./tmp/data', transform=frame_transform, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cf6be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = iter(DataLoader(train_dataset, batch_size=len(train_dataset)//3,\n",
    "                          collate_fn=tonic.collation.PadTensors(batch_first=True), drop_last=True, shuffle=True))\n",
    "        \n",
    "x_train, y_train = next(train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff2544a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_dl = iter(DataLoader(test_dataset, batch_size=len(test_dataset),\n",
    "#                          collate_fn=tonic.collation.PadTensors(batch_first=True), drop_last=True, shuffle=False))\n",
    "#        \n",
    "#x_test, y_test = next(test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "670ea0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = jnp.array(x_train, dtype=jnp.uint8)\n",
    "y_train = jnp.array(y_train, dtype=jnp.uint8)\n",
    "\n",
    "#x_test = jnp.array(x_test, dtype=jnp.uint8)\n",
    "#y_test = jnp.array(y_test, dtype=jnp.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7135a5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(dataset, shuffle_rng, batch_size):\n",
    "    x, y = dataset\n",
    "\n",
    "    cutoff = y.shape[0] % batch_size\n",
    "\n",
    "    obs = jax.random.permutation(shuffle_rng, x, axis=0)[:-cutoff] # this is a bug if cutoff == 0\n",
    "    labels = jax.random.permutation(shuffle_rng, y, axis=0)[:-cutoff]\n",
    "    print(labels.shape)\n",
    "\n",
    "    obs = jnp.reshape(obs, (-1, batch_size) + obs.shape[1:])\n",
    "    labels = jnp.reshape(labels, (-1, batch_size)) # should make batch size a global\n",
    "\n",
    "    return State(obs=obs, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f415eb8",
   "metadata": {},
   "source": [
    "### Spyx NMNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ddc797e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_snn(batch_size):\n",
    "\n",
    "    def nmnist_snn(x): \n",
    "        \n",
    "        core = hk.DeepRNN([\n",
    "            hk.Conv2D(12, 5),\n",
    "            spyx.nn.IF((2, 34, 12,), activation=spyx.axn.Axon(spyx.axn.arctan())),\n",
    "            hk.MaxPool((2,2), (2,2), \"SAME\"),\n",
    "            hk.Conv2D(32, 5),\n",
    "            spyx.nn.LIF((2, 17, 32,), activation=spyx.axn.Axon(spyx.axn.arctan())),\n",
    "            hk.MaxPool((2,2), (2,2), \"SAME\"),\n",
    "            hk.Flatten(),\n",
    "            hk.Linear(10, with_bias=False),\n",
    "            spyx.nn.LIF((10,), activation=spyx.axn.Axon(spyx.axn.arctan()))\n",
    "        ])\n",
    "        \n",
    "        # static unroll for maximum performance\n",
    "        spikes, V = hk.dynamic_unroll(core, x.astype(jnp.float32), core.initial_state(x.shape[0]), time_major=False, unroll=16)\n",
    "    \n",
    "        return spikes, V\n",
    "    \n",
    "    key = jax.random.PRNGKey(0)\n",
    "    # Since there's nothing stochastic about the network, we can avoid using an RNG as a param!\n",
    "    sample_x, sample_y = shuffle((x_train,y_train),key, batch_size)\n",
    "    print(sample_x.shape)\n",
    "    SNN = hk.without_apply_rng(hk.transform(nmnist_snn))\n",
    "    params = SNN.init(rng=key, x=jnp.float32(sample_x[0]))\n",
    "    \n",
    "    return SNN, params\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f7422a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(SNN, params, dataset, epochs, batch_size):\n",
    "        \n",
    "    opt = optax.adam(learning_rate=5e-4)\n",
    "    \n",
    "    # create and initialize the optimizer\n",
    "    opt_state = opt.init(params)\n",
    "    grad_params = params\n",
    "        \n",
    "    # define and compile our eval function that computes the loss for our SNN\n",
    "    @jax.jit\n",
    "    def net_eval(weights, events, targets):\n",
    "        readout = SNN.apply(weights, events)\n",
    "        traces, V_f = readout\n",
    "        return spyx.fn.integral_crossentropy(traces, targets) # smoothing needs to be more explicit in docs...\n",
    "        \n",
    "    # Use JAX to create a function that calculates the loss and the gradient!\n",
    "    surrogate_grad = jax.value_and_grad(net_eval) \n",
    "        \n",
    "    rng = jax.random.PRNGKey(0)        \n",
    "    \n",
    "    # compile the meat of our training loop for speed\n",
    "    @jax.jit\n",
    "    def train_step(state, data):\n",
    "        grad_params, opt_state = state\n",
    "        events, targets = data # fix this\n",
    "        events = jnp.unpackbits(events, axis=1) # decompress temporal axis\n",
    "        # compute loss and gradient                    # need better augment rng\n",
    "        loss, grads = surrogate_grad(grad_params, events, targets)\n",
    "        # generate updates based on the gradients and optimizer\n",
    "        updates, opt_state = opt.update(grads, opt_state, grad_params)\n",
    "        # return the updated parameters\n",
    "        new_state = [optax.apply_updates(grad_params, updates), opt_state]\n",
    "        return new_state, loss\n",
    "    \n",
    "    \n",
    "    # Here's the start of our training loop!\n",
    "    @scan_tqdm(epochs)\n",
    "    def epoch(epoch_state, epoch_num):\n",
    "        curr_params, curr_opt_state = epoch_state\n",
    "\n",
    "        shuffle_rng = jax.random.fold_in(rng, epoch_num)\n",
    "        train_data = shuffle(dataset, shuffle_rng, batch_size)\n",
    "        \n",
    "        # train epoch\n",
    "        end_state, train_loss = jax.lax.scan(\n",
    "            train_step,# func\n",
    "            [curr_params, curr_opt_state],# init\n",
    "            train_data,# xs\n",
    "            train_data.obs.shape[0]# len\n",
    "        )\n",
    "                    \n",
    "        return end_state, jnp.mean(train_loss)\n",
    "    # end epoch\n",
    "    \n",
    "    # epoch loop\n",
    "    final_state, metrics = jax.lax.scan(\n",
    "        epoch,\n",
    "        [grad_params, opt_state], # metric arrays\n",
    "        jnp.arange(epochs), # \n",
    "        epochs # len of loop\n",
    "    )\n",
    "    \n",
    "    final_params, _ = final_state\n",
    "    \n",
    "                \n",
    "    # return our final, optimized network.       \n",
    "    return final_params, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a5cb1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "def run_bench(trials, num_epochs, batch_size):\n",
    "    \n",
    "    SNN, params = build_snn(batch_size)\n",
    "\n",
    "    times = []\n",
    "    for t in range(trials+1):\n",
    "        print(t, \":\", end=\"\")\n",
    "        start = time()\n",
    "        benchmark(SNN, params, (x_train,y_train), num_epochs, batch_size)\n",
    "        times.append(time() - start)\n",
    "        print(times[t])\n",
    "    \n",
    "    print(\"Mean:\", np.mean(times[1:]), \"Std. Dev.:\", np.std(times[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd08a737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49984,)\n",
      "(1562, 32, 8, 2, 34, 34)\n",
      "0 :(49984,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc2601bfff7455daf83bd0575ace046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166.84630870819092\n",
      "1 :(49984,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5cda3277f814fc9ad54186c0644b2c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166.1280755996704\n",
      "2 :(49984,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "850d79d9f52c4e38bd9a166e43a1dde6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165.97760009765625\n",
      "3 :(49984,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d147b24af5408a8628903124ac94d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166.11146712303162\n",
      "4 :(49984,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068ce3471a194c65932def11bf5ed8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166.00985074043274\n",
      "5 :(49984,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6452b62720d64962bcd66c1d284cea47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166.16814804077148\n",
      "Mean: 166.0790283203125 Std. Dev.: 0.07276463154332144\n"
     ]
    }
   ],
   "source": [
    "run_bench(5, 10, 32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
